# Kaggle - House Prices: Advanced Regression Techniques
![Python](https://img.shields.io/badge/python-2.x-orange.svg)
![Type](https://img.shields.io/badge/Machine-Learning-red.svg) ![Type](https://img.shields.io/badge/Type-Supervised-yellow.svg)

With 79 explanatory variables describing almost every aspect of residential homes in Ames, Iowa, this 
competition challenges the data science community to predict the final price of each home.

### Data
train.csv: 1460 houses with 81 attributes, including the labels (sale prices)<br>
test.csv: 1459 houses with 80 attributes<br>
data_description.txt: full description of each column of the csv files

### Results
Feature engineering and a solution using Kernel Ridge regression are shown in [Kernel_Ridge.ipynb](Kernel_Ridge.ipynb).

### Required libraries
- ``NumPy``
- ``Pandas``
- ``scikit-learn``
- ``scipy``
- ``seaborn``
- ``matplotlib``
- ``XGBoost``

### Reference
[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
## Team
- [Jithin K Haridas](https://github.com/jithinharidas)
- [Satyak C](https://github.com/satyak3)
